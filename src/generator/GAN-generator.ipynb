{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Input, Model,Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, UpSampling2D,LeakyReLU\n",
    "from keras.layers import BatchNormalization, Dropout, Add\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape, LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subpixel(Conv2D):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 r,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 strides=(1,1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Subpixel, self).__init__(\n",
    "            filters=r*r*filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _phase_shift(self, I):\n",
    "        r = self.r\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        bsize = K.shape(I)[0] # Handling Dimension(None) type for undefined batch dim\n",
    "        X = K.reshape(I, [bsize, a, b, int(c/(r*r)),r, r]) # bsize, a, b, c/(r*r), r, r\n",
    "        X = K.permute_dimensions(X, (0, 1, 2, 5, 4, 3))  # bsize, a, b, r, r, c/(r*r)\n",
    "        #Keras backend does not support tf.split, so in future versions this could be nicer\n",
    "        X = [X[:,i,:,:,:,:] for i in range(a)] # a, [bsize, b, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, b, a*r, r, c/(r*r)\n",
    "        X = [X[:,i,:,:,:] for i in range(b)] # b, [bsize, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, a*r, b*r, c/(r*r)\n",
    "        return X\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self._phase_shift(super(Subpixel, self).call(inputs))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        unshifted = super(Subpixel, self).compute_output_shape(input_shape)\n",
    "        return (unshifted[0], self.r*unshifted[1], self.r*unshifted[2], unshifted[3]/(self.r*self.r))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        config.pop('dilation_rate')\n",
    "        config['filters']/=self.r*self.r\n",
    "        config['r'] = self.r\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeGeneratorFactory():\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "            Returns a generator Model described here: https://arxiv.org/pdf/1708.05509.pdf\n",
    "            \n",
    "            Args:\n",
    "                input_same: A 3 length tuple describing (width, height, channel)\n",
    "                \n",
    "            Output:\n",
    "                Keras Model\n",
    "        \"\"\"\n",
    "        MOMENTUM = 0.9\n",
    "        DIM = 16\n",
    "        DEPTH = 64\n",
    "        NUM_RESIDUAL = 16\n",
    "        NUM_SUBPIXEL = 3\n",
    "        FINAL_FILTERS = 3\n",
    "        INITIAL_FILTERS = 64\n",
    "        def residual_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                Residual Block consisting of\n",
    "                    Conv2D -> Batch Normalization -> relu -> Conv2D -> Batch Normalization -> Residual Addition\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            shortcut = layer\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "\n",
    "            layer = Add()([layer, shortcut])\n",
    "            return layer\n",
    "        \n",
    "        def residual_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for residual block.\n",
    "                \n",
    "                Creates Residual layer with specified number of residual blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of residual blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = residual_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        \n",
    "        def subpixel_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                sub-pixel block consisting of\n",
    "                    Conv2D -> pixel shuffler x 2 -> Batch Normalization -> Relu\n",
    "                    \n",
    "                the code of subpixel layer is based on https://github.com/Tetrachrome/subpixel\n",
    "                    \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "           \n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = Subpixel(filters, (3,3), 2)(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            return layer\n",
    "        \n",
    "        def subpixel_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for subpixel block.\n",
    "                \n",
    "                Creates subpixel layer with specified number of subpixel blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of subpixel blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = subpixel_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        inputs = Input(shape=input_shape)\n",
    "        filters = INITIAL_FILTERS\n",
    "        layer = Dense(DEPTH*DIM*DIM)(inputs)\n",
    "\n",
    "        layer = BatchNormalization(momentum = MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Reshape((DIM,DIM,DEPTH))(layer)\n",
    "        old = layer\n",
    "        print(\"starting layer built\")\n",
    "        # 16 residual layers\n",
    "        layer = residual_layer(layer, NUM_RESIDUAL, filters, MOMENTUM)\n",
    "    \n",
    "        \n",
    "        layer = BatchNormalization(momentum = MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        print(layer.shape)\n",
    "        layer = Add()([layer, old])\n",
    "        \n",
    "        print(\"residual layer built\")\n",
    "\n",
    "        Model(input = inputs, output = layer).summary()\n",
    "        filters *= 4\n",
    "        # 3 sub-pixel layers\n",
    "        layer = subpixel_layer(layer, NUM_SUBPIXEL, filters, MOMENTUM)\n",
    "\n",
    "        print(\"sub-pixel layer built\")\n",
    "        \n",
    "        layer = Conv2D(filters=FINAL_FILTERS, kernel_size=(9, 9), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = Activation('tanh')(layer)\n",
    "        \n",
    "        print(\"final layer built\")\n",
    "        return Model(input = inputs, output = layer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting layer built\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 16, 16, 64)\nresidual layer built\n____________________________________________________________________________________________________\nLayer (type)                     Output Shape          Param #     Connected to                     \n====================================================================================================\ninput_1 (InputLayer)             (None, 100)           0                                            \n____________________________________________________________________________________________________\ndense_1 (Dense)                  (None, 16384)         1654784     input_1[0][0]                    \n____________________________________________________________________________________________________\nbatch_normalization_1 (BatchNorm (None, 16384)         65536       dense_1[0][0]                    \n____________________________________________________________________________________________________\nactivation_1 (Activation)        (None, 16384)         0           batch_normalization_1[0][0]      \n____________________________________________________________________________________________________\nreshape_1 (Reshape)              (None, 16, 16, 64)    0           activation_1[0][0]               \n____________________________________________________________________________________________________\nconv2d_transpose_1 (Conv2DTransp (None, 16, 16, 64)    36928       reshape_1[0][0]                  \n____________________________________________________________________________________________________\nbatch_normalization_2 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_1[0][0]         \n____________________________________________________________________________________________________\nactivation_2 (Activation)        (None, 16, 16, 64)    0           batch_normalization_2[0][0]      \n____________________________________________________________________________________________________\nconv2d_transpose_2 (Conv2DTransp (None, 16, 16, 64)    36928       activation_2[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_3 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_2[0][0]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:122: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ad..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\nadd_1 (Add)                      (None, 16, 16, 64)    0           batch_normalization_3[0][0]      \n                                                                   reshape_1[0][0]                  \n____________________________________________________________________________________________________\nconv2d_transpose_3 (Conv2DTransp (None, 16, 16, 64)    36928       add_1[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_4 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_3[0][0]         \n____________________________________________________________________________________________________\nactivation_3 (Activation)        (None, 16, 16, 64)    0           batch_normalization_4[0][0]      \n____________________________________________________________________________________________________\nconv2d_transpose_4 (Conv2DTransp (None, 16, 16, 64)    36928       activation_3[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_5 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_4[0][0]         \n____________________________________________________________________________________________________\nadd_2 (Add)                      (None, 16, 16, 64)    0           batch_normalization_5[0][0]      \n                                                                   add_1[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_5 (Conv2DTransp (None, 16, 16, 64)    36928       add_2[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_6 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_5[0][0]         \n____________________________________________________________________________________________________\nactivation_4 (Activation)        (None, 16, 16, 64)    0           batch_normalization_6[0][0]      \n____________________________________________________________________________________________________\nconv2d_transpose_6 (Conv2DTransp (None, 16, 16, 64)    36928       activation_4[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_7 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_6[0][0]         \n____________________________________________________________________________________________________\nadd_3 (Add)                      (None, 16, 16, 64)    0           batch_normalization_7[0][0]      \n                                                                   add_2[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_7 (Conv2DTransp (None, 16, 16, 64)    36928       add_3[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_8 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_7[0][0]         \n____________________________________________________________________________________________________\nactivation_5 (Activation)        (None, 16, 16, 64)    0           batch_normalization_8[0][0]      \n____________________________________________________________________________________________________\nconv2d_transpose_8 (Conv2DTransp (None, 16, 16, 64)    36928       activation_5[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_9 (BatchNorm (None, 16, 16, 64)    256         conv2d_transpose_8[0][0]         \n____________________________________________________________________________________________________\nadd_4 (Add)                      (None, 16, 16, 64)    0           batch_normalization_9[0][0]      \n                                                                   add_3[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_9 (Conv2DTransp (None, 16, 16, 64)    36928       add_4[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_10 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_9[0][0]         \n____________________________________________________________________________________________________\nactivation_6 (Activation)        (None, 16, 16, 64)    0           batch_normalization_10[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_10 (Conv2DTrans (None, 16, 16, 64)    36928       activation_6[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_11 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_10[0][0]        \n____________________________________________________________________________________________________\nadd_5 (Add)                      (None, 16, 16, 64)    0           batch_normalization_11[0][0]     \n                                                                   add_4[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_11 (Conv2DTrans (None, 16, 16, 64)    36928       add_5[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_12 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_11[0][0]        \n____________________________________________________________________________________________________\nactivation_7 (Activation)        (None, 16, 16, 64)    0           batch_normalization_12[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_12 (Conv2DTrans (None, 16, 16, 64)    36928       activation_7[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_13 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_12[0][0]        \n____________________________________________________________________________________________________\nadd_6 (Add)                      (None, 16, 16, 64)    0           batch_normalization_13[0][0]     \n                                                                   add_5[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_13 (Conv2DTrans (None, 16, 16, 64)    36928       add_6[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_14 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_13[0][0]        \n____________________________________________________________________________________________________\nactivation_8 (Activation)        (None, 16, 16, 64)    0           batch_normalization_14[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_14 (Conv2DTrans (None, 16, 16, 64)    36928       activation_8[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_15 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_14[0][0]        \n____________________________________________________________________________________________________\nadd_7 (Add)                      (None, 16, 16, 64)    0           batch_normalization_15[0][0]     \n                                                                   add_6[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_15 (Conv2DTrans (None, 16, 16, 64)    36928       add_7[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_16 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_15[0][0]        \n____________________________________________________________________________________________________\nactivation_9 (Activation)        (None, 16, 16, 64)    0           batch_normalization_16[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_16 (Conv2DTrans (None, 16, 16, 64)    36928       activation_9[0][0]               \n____________________________________________________________________________________________________\nbatch_normalization_17 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_16[0][0]        \n____________________________________________________________________________________________________\nadd_8 (Add)                      (None, 16, 16, 64)    0           batch_normalization_17[0][0]     \n                                                                   add_7[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_17 (Conv2DTrans (None, 16, 16, 64)    36928       add_8[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_18 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_17[0][0]        \n____________________________________________________________________________________________________\nactivation_10 (Activation)       (None, 16, 16, 64)    0           batch_normalization_18[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_18 (Conv2DTrans (None, 16, 16, 64)    36928       activation_10[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_19 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_18[0][0]        \n____________________________________________________________________________________________________\nadd_9 (Add)                      (None, 16, 16, 64)    0           batch_normalization_19[0][0]     \n                                                                   add_8[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_19 (Conv2DTrans (None, 16, 16, 64)    36928       add_9[0][0]                      \n____________________________________________________________________________________________________\nbatch_normalization_20 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_19[0][0]        \n____________________________________________________________________________________________________\nactivation_11 (Activation)       (None, 16, 16, 64)    0           batch_normalization_20[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_20 (Conv2DTrans (None, 16, 16, 64)    36928       activation_11[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_21 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_20[0][0]        \n____________________________________________________________________________________________________\nadd_10 (Add)                     (None, 16, 16, 64)    0           batch_normalization_21[0][0]     \n                                                                   add_9[0][0]                      \n____________________________________________________________________________________________________\nconv2d_transpose_21 (Conv2DTrans (None, 16, 16, 64)    36928       add_10[0][0]                     \n____________________________________________________________________________________________________\nbatch_normalization_22 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_21[0][0]        \n____________________________________________________________________________________________________\nactivation_12 (Activation)       (None, 16, 16, 64)    0           batch_normalization_22[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_22 (Conv2DTrans (None, 16, 16, 64)    36928       activation_12[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_23 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_22[0][0]        \n____________________________________________________________________________________________________\nadd_11 (Add)                     (None, 16, 16, 64)    0           batch_normalization_23[0][0]     \n                                                                   add_10[0][0]                     \n____________________________________________________________________________________________________\nconv2d_transpose_23 (Conv2DTrans (None, 16, 16, 64)    36928       add_11[0][0]                     \n____________________________________________________________________________________________________\nbatch_normalization_24 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_23[0][0]        \n____________________________________________________________________________________________________\nactivation_13 (Activation)       (None, 16, 16, 64)    0           batch_normalization_24[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_24 (Conv2DTrans (None, 16, 16, 64)    36928       activation_13[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_25 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_24[0][0]        \n____________________________________________________________________________________________________\nadd_12 (Add)                     (None, 16, 16, 64)    0           batch_normalization_25[0][0]     \n                                                                   add_11[0][0]                     \n____________________________________________________________________________________________________\nconv2d_transpose_25 (Conv2DTrans (None, 16, 16, 64)    36928       add_12[0][0]                     \n____________________________________________________________________________________________________\nbatch_normalization_26 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_25[0][0]        \n____________________________________________________________________________________________________\nactivation_14 (Activation)       (None, 16, 16, 64)    0           batch_normalization_26[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_26 (Conv2DTrans (None, 16, 16, 64)    36928       activation_14[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_27 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_26[0][0]        \n____________________________________________________________________________________________________\nadd_13 (Add)                     (None, 16, 16, 64)    0           batch_normalization_27[0][0]     \n                                                                   add_12[0][0]                     \n____________________________________________________________________________________________________\nconv2d_transpose_27 (Conv2DTrans (None, 16, 16, 64)    36928       add_13[0][0]                     \n____________________________________________________________________________________________________\nbatch_normalization_28 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_27[0][0]        \n____________________________________________________________________________________________________\nactivation_15 (Activation)       (None, 16, 16, 64)    0           batch_normalization_28[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_28 (Conv2DTrans (None, 16, 16, 64)    36928       activation_15[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_29 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_28[0][0]        \n____________________________________________________________________________________________________\nadd_14 (Add)                     (None, 16, 16, 64)    0           batch_normalization_29[0][0]     \n                                                                   add_13[0][0]                     \n____________________________________________________________________________________________________\nconv2d_transpose_29 (Conv2DTrans (None, 16, 16, 64)    36928       add_14[0][0]                     \n____________________________________________________________________________________________________\nbatch_normalization_30 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_29[0][0]        \n____________________________________________________________________________________________________\nactivation_16 (Activation)       (None, 16, 16, 64)    0           batch_normalization_30[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_30 (Conv2DTrans (None, 16, 16, 64)    36928       activation_16[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_31 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_30[0][0]        \n____________________________________________________________________________________________________\nadd_15 (Add)                     (None, 16, 16, 64)    0           batch_normalization_31[0][0]     \n                                                                   add_14[0][0]                     \n____________________________________________________________________________________________________\nconv2d_transpose_31 (Conv2DTrans (None, 16, 16, 64)    36928       add_15[0][0]                     \n____________________________________________________________________________________________________\nbatch_normalization_32 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_31[0][0]        \n____________________________________________________________________________________________________\nactivation_17 (Activation)       (None, 16, 16, 64)    0           batch_normalization_32[0][0]     \n____________________________________________________________________________________________________\nconv2d_transpose_32 (Conv2DTrans (None, 16, 16, 64)    36928       activation_17[0][0]              \n____________________________________________________________________________________________________\nbatch_normalization_33 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_32[0][0]        \n____________________________________________________________________________________________________\nadd_16 (Add)                     (None, 16, 16, 64)    0           batch_normalization_33[0][0]     \n                                                                   add_15[0][0]                     \n____________________________________________________________________________________________________\nbatch_normalization_34 (BatchNor (None, 16, 16, 64)    256         add_16[0][0]                     \n____________________________________________________________________________________________________\nactivation_18 (Activation)       (None, 16, 16, 64)    0           batch_normalization_34[0][0]     \n____________________________________________________________________________________________________\nadd_17 (Add)                     (None, 16, 16, 64)    0           activation_18[0][0]              \n                                                                   reshape_1[0][0]                  \n====================================================================================================\nTotal params: 2,910,464\nTrainable params: 2,873,472\nNon-trainable params: 36,992\n____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.uniform(-1.0, 1.0, size=[256, 100])\n",
    "shape = (64,64,3)\n",
    "generator = AnimeGeneratorFactory().build([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnimeDiscriminatorFactory' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c0d07c6efe3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexpected_anime_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdiscriminator_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnimeDiscriminatorFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator_factory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_anime_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AnimeDiscriminatorFactory' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "expected_anime_image = (64, 64, 3)\n",
    "discriminator_factory = AnimeDiscriminatorFactory()\n",
    "model = discriminator_factory.build(expected_anime_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
