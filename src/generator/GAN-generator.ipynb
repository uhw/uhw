{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import datetime\n",
    "from keras.models import Input, Model,Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, UpSampling2D,LeakyReLU\n",
    "from keras.layers import BatchNormalization, Dropout, Add\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape, LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subpixel(Conv2D):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 r,\n",
    "                 padding='same',\n",
    "                 data_format=None,\n",
    "                 strides=(1,1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Subpixel, self).__init__(\n",
    "            filters=r*r*filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _phase_shift(self, I):\n",
    "        r = self.r\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        bsize = K.shape(I)[0] # Handling Dimension(None) type for undefined batch dim\n",
    "        X = K.reshape(I, [bsize, a, b, int(c/(r*r)),r, r]) # bsize, a, b, c/(r*r), r, r\n",
    "        X = K.permute_dimensions(X, (0, 1, 2, 5, 4, 3))  # bsize, a, b, r, r, c/(r*r)\n",
    "        #Keras backend does not support tf.split, so in future versions this could be nicer\n",
    "        X = [X[:,i,:,:,:,:] for i in range(a)] # a, [bsize, b, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, b, a*r, r, c/(r*r)\n",
    "        X = [X[:,i,:,:,:] for i in range(b)] # b, [bsize, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, a*r, b*r, c/(r*r)\n",
    "        return X\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self._phase_shift(super(Subpixel, self).call(inputs))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        unshifted = super(Subpixel, self).compute_output_shape(input_shape)\n",
    "        return (unshifted[0], int(self.r*unshifted[1]), int(self.r*unshifted[2]), int(unshifted[3]/(self.r*self.r)))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        config.pop('dilation_rate')\n",
    "        config['filters']/=int(self.r*self.r)\n",
    "        config['r'] = self.r\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnimeGeneratorFactory():\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "            Returns a generator Model described here: https://arxiv.org/pdf/1708.05509.pdf\n",
    "            \n",
    "            Args:\n",
    "                input_same: A 3 length tuple describing (width, height, channel)\n",
    "                \n",
    "            Output:\n",
    "                Keras Model\n",
    "        \"\"\"\n",
    "        MOMENTUM = 0.9\n",
    "        DIM = 16\n",
    "        DEPTH = 64\n",
    "        NUM_RESIDUAL = 16\n",
    "        NUM_SUBPIXEL = 2\n",
    "        FINAL_FILTERS = 3\n",
    "        INITIAL_FILTERS = 64\n",
    "        def residual_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                Residual Block consisting of\n",
    "                    Conv2D -> Batch Normalization -> relu -> Conv2D -> Batch Normalization -> Residual Addition\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            shortcut = layer\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "\n",
    "            layer = Add()([layer, shortcut])\n",
    "            return layer\n",
    "        \n",
    "        def residual_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for residual block.\n",
    "                \n",
    "                Creates Residual layer with specified number of residual blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of residual blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = residual_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        \n",
    "        def subpixel_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                sub-pixel block consisting of\n",
    "                    Conv2D -> pixel shuffler x 2 -> Batch Normalization -> Relu\n",
    "                    \n",
    "                the code of subpixel layer is based on https://github.com/Tetrachrome/subpixel\n",
    "                    \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"  \n",
    "            \n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = Subpixel(filters, (3,3), 2)(layer)\n",
    "\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            return layer\n",
    "        \n",
    "        def subpixel_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for subpixel block.\n",
    "                \n",
    "                Creates subpixel layer with specified number of subpixel blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of subpixel blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = subpixel_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        inputs = Input(shape=input_shape)\n",
    "        filters = INITIAL_FILTERS\n",
    "        layer = Dense(DEPTH*DIM*DIM)(inputs)\n",
    "\n",
    "        layer = BatchNormalization(momentum = MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Reshape((DIM,DIM,DEPTH))(layer)\n",
    "        old = layer\n",
    "        print(\"starting layer built\")\n",
    "        # 16 residual layers\n",
    "        layer = residual_layer(layer, NUM_RESIDUAL, filters, MOMENTUM)\n",
    "    \n",
    "        \n",
    "        layer = BatchNormalization(momentum = MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Add()([layer, old])\n",
    "        \n",
    "        print(\"residual layer built\")\n",
    "\n",
    "        filters *= 4\n",
    "        # 3 sub-pixel layers\n",
    "        layer = subpixel_layer(layer, NUM_SUBPIXEL, filters, MOMENTUM)\n",
    "\n",
    "        print(\"sub-pixel layer built\")\n",
    "        \n",
    "        layer = Conv2D(filters=FINAL_FILTERS, kernel_size=(9, 9), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = Activation('tanh')(layer)\n",
    "        \n",
    "        print(\"final layer built\")\n",
    "        return Model(input = inputs, output = layer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting layer built\n",
      "residual layer built\n",
      "sub-pixel layer built\n",
      "final layer built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:132: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "generator = AnimeGeneratorFactory().build([128+34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_52 (InputLayer)            (None, 162)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_52 (Dense)                 (None, 16384)         2670592     input_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1812 (BatchN (None, 16384)         65536       dense_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1011 (Activation)     (None, 16384)         0           batch_normalization_1812[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_52 (Reshape)             (None, 16, 16, 64)    0           activation_1011[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1661 (Conv2DTra (None, 16, 16, 64)    36928       reshape_52[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1813 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1661[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1012 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1813[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1662 (Conv2DTra (None, 16, 16, 64)    36928       activation_1012[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1814 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1662[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_868 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1814[0][0]   \n",
      "                                                                   reshape_52[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1663 (Conv2DTra (None, 16, 16, 64)    36928       add_868[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1815 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1663[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1013 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1815[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1664 (Conv2DTra (None, 16, 16, 64)    36928       activation_1013[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1816 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1664[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_869 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1816[0][0]   \n",
      "                                                                   add_868[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1665 (Conv2DTra (None, 16, 16, 64)    36928       add_869[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1817 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1665[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1014 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1817[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1666 (Conv2DTra (None, 16, 16, 64)    36928       activation_1014[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1818 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1666[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_870 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1818[0][0]   \n",
      "                                                                   add_869[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1667 (Conv2DTra (None, 16, 16, 64)    36928       add_870[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1819 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1667[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1015 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1819[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1668 (Conv2DTra (None, 16, 16, 64)    36928       activation_1015[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1820 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1668[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_871 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1820[0][0]   \n",
      "                                                                   add_870[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1669 (Conv2DTra (None, 16, 16, 64)    36928       add_871[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1821 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1669[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1016 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1821[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1670 (Conv2DTra (None, 16, 16, 64)    36928       activation_1016[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1822 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1670[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_872 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1822[0][0]   \n",
      "                                                                   add_871[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1671 (Conv2DTra (None, 16, 16, 64)    36928       add_872[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1823 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1671[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1017 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1823[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1672 (Conv2DTra (None, 16, 16, 64)    36928       activation_1017[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1824 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1672[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_873 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1824[0][0]   \n",
      "                                                                   add_872[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1673 (Conv2DTra (None, 16, 16, 64)    36928       add_873[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1825 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1673[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1018 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1825[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1674 (Conv2DTra (None, 16, 16, 64)    36928       activation_1018[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1826 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1674[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_874 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1826[0][0]   \n",
      "                                                                   add_873[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1675 (Conv2DTra (None, 16, 16, 64)    36928       add_874[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1827 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1675[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1019 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1827[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1676 (Conv2DTra (None, 16, 16, 64)    36928       activation_1019[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1828 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1676[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_875 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1828[0][0]   \n",
      "                                                                   add_874[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1677 (Conv2DTra (None, 16, 16, 64)    36928       add_875[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1829 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1677[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1020 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1829[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1678 (Conv2DTra (None, 16, 16, 64)    36928       activation_1020[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1830 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1678[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_876 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1830[0][0]   \n",
      "                                                                   add_875[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1679 (Conv2DTra (None, 16, 16, 64)    36928       add_876[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1831 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1679[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1021 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1831[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1680 (Conv2DTra (None, 16, 16, 64)    36928       activation_1021[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1832 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1680[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_877 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1832[0][0]   \n",
      "                                                                   add_876[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1681 (Conv2DTra (None, 16, 16, 64)    36928       add_877[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1833 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1681[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1022 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1833[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1682 (Conv2DTra (None, 16, 16, 64)    36928       activation_1022[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1834 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1682[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_878 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1834[0][0]   \n",
      "                                                                   add_877[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1683 (Conv2DTra (None, 16, 16, 64)    36928       add_878[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1835 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1683[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1023 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1835[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1684 (Conv2DTra (None, 16, 16, 64)    36928       activation_1023[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1836 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1684[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_879 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1836[0][0]   \n",
      "                                                                   add_878[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1685 (Conv2DTra (None, 16, 16, 64)    36928       add_879[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1837 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1685[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1024 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1837[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1686 (Conv2DTra (None, 16, 16, 64)    36928       activation_1024[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1838 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1686[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_880 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1838[0][0]   \n",
      "                                                                   add_879[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1687 (Conv2DTra (None, 16, 16, 64)    36928       add_880[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1839 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1687[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1025 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1839[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1688 (Conv2DTra (None, 16, 16, 64)    36928       activation_1025[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1840 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1688[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_881 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1840[0][0]   \n",
      "                                                                   add_880[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1689 (Conv2DTra (None, 16, 16, 64)    36928       add_881[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1841 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1689[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1026 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1841[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1690 (Conv2DTra (None, 16, 16, 64)    36928       activation_1026[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1842 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1690[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_882 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1842[0][0]   \n",
      "                                                                   add_881[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1691 (Conv2DTra (None, 16, 16, 64)    36928       add_882[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1843 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1691[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1027 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1843[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1692 (Conv2DTra (None, 16, 16, 64)    36928       activation_1027[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1844 (BatchN (None, 16, 16, 64)    256         conv2d_transpose_1692[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "add_883 (Add)                    (None, 16, 16, 64)    0           batch_normalization_1844[0][0]   \n",
      "                                                                   add_882[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1845 (BatchN (None, 16, 16, 64)    256         add_883[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1028 (Activation)     (None, 16, 16, 64)    0           batch_normalization_1845[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "add_884 (Add)                    (None, 16, 16, 64)    0           activation_1028[0][0]            \n",
      "                                                                   reshape_52[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 16, 16, 256)   147712      add_884[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "subpixel_124 (Subpixel)          (None, 32, 32, 256)   2360320     conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1846 (BatchN (None, 32, 32, 256)   1024        subpixel_124[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1029 (Activation)     (None, 32, 32, 256)   0           batch_normalization_1846[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 32, 32, 256)   590080      activation_1029[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "subpixel_125 (Subpixel)          (None, 64, 64, 256)   2360320     conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1847 (BatchN (None, 64, 64, 256)   1024        subpixel_125[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1030 (Activation)     (None, 64, 64, 256)   0           batch_normalization_1847[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 64, 64, 3)     62211       activation_1030[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1031 (Activation)     (None, 64, 64, 3)     0           conv2d_59[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 9,448,963\n",
      "Trainable params: 9,410,947\n",
      "Non-trainable params: 38,016\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (generator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Node 'batch_normalization_1848/cond/Switch': Unknown input node 'batch_normalization_1/keras_learning_phase'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1296\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1358\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Node 'batch_normalization_1848/cond/Switch': Unknown input node 'batch_normalization_1/keras_learning_phase'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-e0fbc39f92de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzsamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m162\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mzsamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1713\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Node 'batch_normalization_1848/cond/Switch': Unknown input node 'batch_normalization_1/keras_learning_phase'"
     ]
    }
   ],
   "source": [
    "zsamples = np.random.normal(size=[10 * 10, 162])\n",
    "zsamples.shape\n",
    "images = generator.predict(zsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
