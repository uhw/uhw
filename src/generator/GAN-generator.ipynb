{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Input, Model,Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, UpSampling2D,LeakyReLU\n",
    "from keras.layers import BatchNormalization, Dropout, Add\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape, LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subpixel(Conv2D):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 r,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 strides=(1,1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Subpixel, self).__init__(\n",
    "            filters=r*r*filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _phase_shift(self, I):\n",
    "        r = self.r\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        bsize = K.shape(I)[0] # Handling Dimension(None) type for undefined batch dim\n",
    "        X = K.reshape(I, [bsize, a, b, int(c/(r*r)),r, r]) # bsize, a, b, c/(r*r), r, r\n",
    "        X = K.permute_dimensions(X, (0, 1, 2, 5, 4, 3))  # bsize, a, b, r, r, c/(r*r)\n",
    "        #Keras backend does not support tf.split, so in future versions this could be nicer\n",
    "        X = [X[:,i,:,:,:,:] for i in range(a)] # a, [bsize, b, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, b, a*r, r, c/(r*r)\n",
    "        X = [X[:,i,:,:,:] for i in range(b)] # b, [bsize, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, a*r, b*r, c/(r*r)\n",
    "        return X\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self._phase_shift(super(Subpixel, self).call(inputs))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        unshifted = super(Subpixel, self).compute_output_shape(input_shape)\n",
    "        return (unshifted[0], self.r*unshifted[1], self.r*unshifted[2], unshifted[3]/(self.r*self.r))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        config.pop('dilation_rate')\n",
    "        config['filters']/=self.r*self.r\n",
    "        config['r'] = self.r\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeGeneratorFactory():\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "            Returns a generator Model described here: https://arxiv.org/pdf/1708.05509.pdf\n",
    "            \n",
    "            Args:\n",
    "                input_same: A 3 length tuple describing (width, height, channel)\n",
    "                \n",
    "            Output:\n",
    "                Keras Model\n",
    "        \"\"\"\n",
    "        MOMENTUM = 0.9\n",
    "        DIM = 16\n",
    "        DEPTH = 64\n",
    "        NUM_RESIDUAL = 16\n",
    "        NUM_SUBPIXEL = 3\n",
    "        FINAL_FILTERS = 3\n",
    "        INITIAL_FILTERS = 64\n",
    "        def residual_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                Residual Block consisting of\n",
    "                    Conv2D -> Batch Normalization -> relu -> Conv2D -> Batch Normalization -> Residual Addition\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            shortcut = layer\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "\n",
    "            layer = Add()([layer, shortcut])\n",
    "            return layer\n",
    "        \n",
    "        def residual_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for residual block.\n",
    "                \n",
    "                Creates Residual layer with specified number of residual blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of residual blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = residual_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        \n",
    "        def subpixel_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                sub-pixel block consisting of\n",
    "                    Conv2D -> pixel shuffler x 2 -> Batch Normalization -> Relu\n",
    "                    \n",
    "                the code of subpixel layer is based on https://github.com/Tetrachrome/subpixel\n",
    "                    \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "           \n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = Subpixel(filters, (3,3), 2)(layer)\n",
    "            layer = BatchNormalization(momentum= momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            return layer\n",
    "        \n",
    "        def subpixel_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for subpixel block.\n",
    "                \n",
    "                Creates subpixel layer with specified number of subpixel blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of subpixel blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = subpixel_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        inputs = Input(shape=input_shape)\n",
    "        filters = INITIAL_FILTERS\n",
    "        layer = Dense(DEPTH*DIM*DIM)(inputs)\n",
    "\n",
    "        layer = BatchNormalization(momentum = MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Reshape((DIM,DIM,DEPTH))(layer)\n",
    "        old = layer\n",
    "        print(\"starting layer built\")\n",
    "        # 16 residual layers\n",
    "        layer = residual_layer(layer, NUM_RESIDUAL, filters, MOMENTUM)\n",
    "    \n",
    "        \n",
    "        layer = BatchNormalization(momentum = MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        print(layer.shape)\n",
    "        layer = Add()([layer, old])\n",
    "        \n",
    "        print(\"residual layer built\")\n",
    "\n",
    "        Model(input = inputs, output = layer).summary()\n",
    "        filters *= 4\n",
    "        # 3 sub-pixel layers\n",
    "        layer = subpixel_layer(layer, NUM_SUBPIXEL, filters, MOMENTUM)\n",
    "\n",
    "        print(\"sub-pixel layer built\")\n",
    "        \n",
    "        layer = Conv2D(filters=FINAL_FILTERS, kernel_size=(9, 9), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = Activation('tanh')(layer)\n",
    "        \n",
    "        print(\"final layer built\")\n",
    "        return Model(input = inputs, output = layer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting layer built\n",
      "(?, 16, 16, 64)\n",
      "residual layer built\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_52 (InputLayer)            (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 16384)         1654784     input_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_805 (BatchNo (None, 16384)         65536       dense_53[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_444 (Activation)      (None, 16384)         0           batch_normalization_805[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)             (None, 16, 16, 64)    0           activation_444[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_729 (Conv2DTran (None, 16, 16, 64)    36928       reshape_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_806 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_729[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_445 (Activation)      (None, 16, 16, 64)    0           batch_normalization_806[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_730 (Conv2DTran (None, 16, 16, 64)    36928       activation_445[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_807 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_730[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_401 (Add)                    (None, 16, 16, 64)    0           batch_normalization_807[0][0]    \n",
      "                                                                   reshape_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_731 (Conv2DTran (None, 16, 16, 64)    36928       add_401[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_808 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_731[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_446 (Activation)      (None, 16, 16, 64)    0           batch_normalization_808[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_732 (Conv2DTran (None, 16, 16, 64)    36928       activation_446[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_809 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_732[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_402 (Add)                    (None, 16, 16, 64)    0           batch_normalization_809[0][0]    \n",
      "                                                                   add_401[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_733 (Conv2DTran (None, 16, 16, 64)    36928       add_402[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_810 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_733[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_447 (Activation)      (None, 16, 16, 64)    0           batch_normalization_810[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_734 (Conv2DTran (None, 16, 16, 64)    36928       activation_447[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_811 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_734[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_403 (Add)                    (None, 16, 16, 64)    0           batch_normalization_811[0][0]    \n",
      "                                                                   add_402[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_735 (Conv2DTran (None, 16, 16, 64)    36928       add_403[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_812 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_735[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_448 (Activation)      (None, 16, 16, 64)    0           batch_normalization_812[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_736 (Conv2DTran (None, 16, 16, 64)    36928       activation_448[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_813 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_736[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_404 (Add)                    (None, 16, 16, 64)    0           batch_normalization_813[0][0]    \n",
      "                                                                   add_403[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_737 (Conv2DTran (None, 16, 16, 64)    36928       add_404[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_814 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_737[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_449 (Activation)      (None, 16, 16, 64)    0           batch_normalization_814[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_738 (Conv2DTran (None, 16, 16, 64)    36928       activation_449[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_815 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_738[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_405 (Add)                    (None, 16, 16, 64)    0           batch_normalization_815[0][0]    \n",
      "                                                                   add_404[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_739 (Conv2DTran (None, 16, 16, 64)    36928       add_405[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_816 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_739[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_450 (Activation)      (None, 16, 16, 64)    0           batch_normalization_816[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_740 (Conv2DTran (None, 16, 16, 64)    36928       activation_450[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_817 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_740[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_406 (Add)                    (None, 16, 16, 64)    0           batch_normalization_817[0][0]    \n",
      "                                                                   add_405[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_741 (Conv2DTran (None, 16, 16, 64)    36928       add_406[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_818 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_741[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_451 (Activation)      (None, 16, 16, 64)    0           batch_normalization_818[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_742 (Conv2DTran (None, 16, 16, 64)    36928       activation_451[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_819 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_742[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_407 (Add)                    (None, 16, 16, 64)    0           batch_normalization_819[0][0]    \n",
      "                                                                   add_406[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_743 (Conv2DTran (None, 16, 16, 64)    36928       add_407[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_820 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_743[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_452 (Activation)      (None, 16, 16, 64)    0           batch_normalization_820[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_744 (Conv2DTran (None, 16, 16, 64)    36928       activation_452[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_821 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_744[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_408 (Add)                    (None, 16, 16, 64)    0           batch_normalization_821[0][0]    \n",
      "                                                                   add_407[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_745 (Conv2DTran (None, 16, 16, 64)    36928       add_408[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_822 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_745[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_453 (Activation)      (None, 16, 16, 64)    0           batch_normalization_822[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_746 (Conv2DTran (None, 16, 16, 64)    36928       activation_453[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_823 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_746[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_409 (Add)                    (None, 16, 16, 64)    0           batch_normalization_823[0][0]    \n",
      "                                                                   add_408[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_747 (Conv2DTran (None, 16, 16, 64)    36928       add_409[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_824 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_747[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_454 (Activation)      (None, 16, 16, 64)    0           batch_normalization_824[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_748 (Conv2DTran (None, 16, 16, 64)    36928       activation_454[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_825 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_748[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_410 (Add)                    (None, 16, 16, 64)    0           batch_normalization_825[0][0]    \n",
      "                                                                   add_409[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_749 (Conv2DTran (None, 16, 16, 64)    36928       add_410[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_826 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_749[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_455 (Activation)      (None, 16, 16, 64)    0           batch_normalization_826[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_750 (Conv2DTran (None, 16, 16, 64)    36928       activation_455[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_827 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_750[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_411 (Add)                    (None, 16, 16, 64)    0           batch_normalization_827[0][0]    \n",
      "                                                                   add_410[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_751 (Conv2DTran (None, 16, 16, 64)    36928       add_411[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_828 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_751[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_456 (Activation)      (None, 16, 16, 64)    0           batch_normalization_828[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_752 (Conv2DTran (None, 16, 16, 64)    36928       activation_456[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_829 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_752[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_412 (Add)                    (None, 16, 16, 64)    0           batch_normalization_829[0][0]    \n",
      "                                                                   add_411[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_753 (Conv2DTran (None, 16, 16, 64)    36928       add_412[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_830 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_753[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_457 (Activation)      (None, 16, 16, 64)    0           batch_normalization_830[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_754 (Conv2DTran (None, 16, 16, 64)    36928       activation_457[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_831 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_754[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_413 (Add)                    (None, 16, 16, 64)    0           batch_normalization_831[0][0]    \n",
      "                                                                   add_412[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_755 (Conv2DTran (None, 16, 16, 64)    36928       add_413[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_832 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_755[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_458 (Activation)      (None, 16, 16, 64)    0           batch_normalization_832[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_756 (Conv2DTran (None, 16, 16, 64)    36928       activation_458[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_833 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_756[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_414 (Add)                    (None, 16, 16, 64)    0           batch_normalization_833[0][0]    \n",
      "                                                                   add_413[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_757 (Conv2DTran (None, 16, 16, 64)    36928       add_414[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_834 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_757[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_459 (Activation)      (None, 16, 16, 64)    0           batch_normalization_834[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_758 (Conv2DTran (None, 16, 16, 64)    36928       activation_459[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_835 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_758[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_415 (Add)                    (None, 16, 16, 64)    0           batch_normalization_835[0][0]    \n",
      "                                                                   add_414[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_759 (Conv2DTran (None, 16, 16, 64)    36928       add_415[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_836 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_759[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_460 (Activation)      (None, 16, 16, 64)    0           batch_normalization_836[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_760 (Conv2DTran (None, 16, 16, 64)    36928       activation_460[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_837 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_760[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "add_416 (Add)                    (None, 16, 16, 64)    0           batch_normalization_837[0][0]    \n",
      "                                                                   add_415[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_838 (BatchNo (None, 16, 16, 64)    256         add_416[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_461 (Activation)      (None, 16, 16, 64)    0           batch_normalization_838[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "add_417 (Add)                    (None, 16, 16, 64)    0           activation_461[0][0]             \n",
      "                                                                   reshape_28[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 2,910,464\n",
      "Trainable params: 2,873,472\n",
      "Non-trainable params: 36,992\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:122: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ad...)`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'shape' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-d4b97eb24b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnimeGeneratorFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-72160abd22de>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mfilters\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# 3 sub-pixel layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubpixel_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SUBPIXEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMOMENTUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sub-pixel layer built\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-72160abd22de>\u001b[0m in \u001b[0;36msubpixel_layer\u001b[0;34m(layer, number, filters, momentum)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \"\"\"\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubpixel_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-72160abd22de>\u001b[0m in \u001b[0;36msubpixel_block\u001b[0;34m(layer, filters, momentum)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \"\"\"\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubpixel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    132\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             self.bias = self.add_weight(shape=(self.filters,),\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    397\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return K.random_uniform(shape, -limit, limit,\n\u001b[0;32m--> 212\u001b[0;31m                                     dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   3542\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3543\u001b[0m     return tf.random_uniform(shape, minval=minval, maxval=maxval,\n\u001b[0;32m-> 3544\u001b[0;31m                              dtype=dtype, seed=seed)\n\u001b[0m\u001b[1;32m   3545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       rnd = gen_random_ops._random_uniform(\n\u001b[0;32m--> 240\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    241\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36m_random_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    245\u001b[0m   \"\"\"\n\u001b[1;32m    246\u001b[0m   result = _op_def_lib.apply_op(\"RandomUniform\", shape=shape, dtype=dtype,\n\u001b[0;32m--> 247\u001b[0;31m                                 seed=seed, seed2=seed2, name=name)\n\u001b[0m\u001b[1;32m    248\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    587\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m    588\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                                        param_name=input_name)\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[0;32m---> 60\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'shape' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "noise = np.random.uniform(-1.0, 1.0, size=[256, 100])\n",
    "shape = (64,64,3)\n",
    "generator = AnimeGeneratorFactory().build([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "expected_anime_image = (64, 64, 3)\n",
    "discriminator_factory = AnimeDiscriminatorFactory()\n",
    "model = discriminator_factory.build(expected_anime_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
