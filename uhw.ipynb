{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf         \n",
    "from keras.layers import BatchNormalization, LeakyReLU, Add\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.models import Input, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as IM\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_image = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_images_from_files_to_list(root, files, list, next_index, data_cb=None):\n",
    "    if files and next_index < num_image:\n",
    "        def identity(v):\n",
    "            return v\n",
    "\n",
    "        if data_cb is None:\n",
    "            data_cb = identity\n",
    "\n",
    "        for index, file in enumerate(files):\n",
    "            if file.endswith('.png'):\n",
    "                image = IM.load_img(os.path.join(root, file))\n",
    "                if image is not None and next_index < num_image:\n",
    "                    list[next_index] = data_cb(image.reshape((64, 64, 3)))\n",
    "                    next_index += 1\n",
    "                # list.append(data_cb(image[:, :, 0]))\n",
    "    return next_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_train = np.empty((num_image, 64, 64, 3))\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, sub_directories, files in os.walk(\"\"):\n",
    "    if i < num_image:\n",
    "        print(i)\n",
    "        i = add_images_from_files_to_list(root, files, images_train, i)\n",
    "\n",
    "# plt.subplot(96, 96)\n",
    "# plt.imshow(images_train[20], interpolation='nearest', cmap='gray_r')\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('./collected_data/gan_generated_image_epoch_%d.png' % 999)\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images_train = np.array(images_train)\n",
    "# images_train = images_train.reshape((*images_train.shape, 1))\n",
    "# images_train = images_train[:, :, :, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout = 0.4\n",
    "depth = 256\n",
    "dim = 8\n",
    "input_dim = 128\n",
    "batch_size = 1\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subpixel(Conv2D):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 r,\n",
    "                 padding='same',\n",
    "                 data_format=None,\n",
    "                 strides=(1,1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Subpixel, self).__init__(\n",
    "            filters=r*r*filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _phase_shift(self, I):\n",
    "        r = self.r\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        bsize = K.shape(I)[0] # Handling Dimension(None) type for undefined batch dim\n",
    "        X = K.reshape(I, [bsize, a, b, int(c/(r*r)),r, r]) # bsize, a, b, c/(r*r), r, r\n",
    "        X = K.permute_dimensions(X, (0, 1, 2, 5, 4, 3))  # bsize, a, b, r, r, c/(r*r)\n",
    "        #Keras backend does not support tf.split, so in future versions this could be nicer\n",
    "        X = [X[:,i,:,:,:,:] for i in range(a)] # a, [bsize, b, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, b, a*r, r, c/(r*r)\n",
    "        X = [X[:,i,:,:,:] for i in range(b)] # b, [bsize, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, a*r, b*r, c/(r*r)\n",
    "        return X\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self._phase_shift(super(Subpixel, self).call(inputs))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        unshifted = super(Subpixel, self).compute_output_shape(input_shape)\n",
    "        return (unshifted[0], int(self.r*unshifted[1]), int(self.r*unshifted[2]), int(unshifted[3]/(self.r*self.r)))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        config.pop('dilation_rate')\n",
    "        config['filters']/=int(self.r*self.r)\n",
    "        config['r'] = self.r\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnimeGeneratorFactory():\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "            Returns a generator Model described here: https://arxiv.org/pdf/1708.05509.pdf\n",
    "            \n",
    "            Args:\n",
    "                input_same: A 3 length tuple describing (width, height, channel)\n",
    "                \n",
    "            Output:\n",
    "                Keras Model\n",
    "        \"\"\"\n",
    "        MOMENTUM = 0.9\n",
    "        DIM = 16\n",
    "        DEPTH = 64\n",
    "        NUM_RESIDUAL = 16\n",
    "        NUM_SUBPIXEL = 2\n",
    "        FINAL_FILTERS = 3\n",
    "        #FINAL_FILTERS = 1\n",
    "        INITIAL_FILTERS = 64\n",
    "        def residual_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                Residual Block consisting of\n",
    "                    Conv2D -> Batch Normalization -> relu -> Conv2D -> Batch Normalization -> Residual Addition\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            shortcut = layer\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum=momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum=momentum)(layer)\n",
    "\n",
    "            layer = Add()([layer, shortcut])\n",
    "            return layer\n",
    "\n",
    "        def residual_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for residual block.\n",
    "                \n",
    "                Creates Residual layer with specified number of residual blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of residual blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = residual_block(layer, filters, momentum)\n",
    "            return layer\n",
    "\n",
    "        def subpixel_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                sub-pixel block consisting of\n",
    "                    Conv2D -> pixel shuffler x 2 -> Batch Normalization -> Relu\n",
    "                    \n",
    "                the code of subpixel layer is based on https://github.com/Tetrachrome/subpixel\n",
    "                    \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "\n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = Subpixel(filters, (3, 3), 2)(layer)\n",
    "\n",
    "            layer = BatchNormalization(momentum=momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            return layer\n",
    "\n",
    "        def subpixel_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for subpixel block.\n",
    "                \n",
    "                Creates subpixel layer with specified number of subpixel blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of subpixel blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = subpixel_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        inputs = Input(shape=input_shape)\n",
    "        filters = INITIAL_FILTERS\n",
    "        layer = Dense(DEPTH * DIM * DIM)(inputs)\n",
    "\n",
    "        layer = BatchNormalization(momentum=MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Reshape((DIM, DIM, DEPTH))(layer)\n",
    "        old = layer\n",
    "        print(\"starting layer built\")\n",
    "        # 16 residual layers\n",
    "        layer = residual_layer(layer, NUM_RESIDUAL, filters, MOMENTUM)\n",
    "\n",
    "        layer = BatchNormalization(momentum=MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Add()([layer, old])\n",
    "\n",
    "        print(\"residual layer built\")\n",
    "\n",
    "        filters *= 4\n",
    "        # 3 sub-pixel layers\n",
    "        layer = subpixel_layer(layer, NUM_SUBPIXEL, filters, MOMENTUM)\n",
    "\n",
    "        print(\"sub-pixel layer built\")\n",
    "\n",
    "        layer = Conv2D(filters=FINAL_FILTERS, kernel_size=(9, 9), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = Activation('tanh')(layer)\n",
    "\n",
    "        print(\"final layer built\")\n",
    "        model = Model(inputs=inputs, outputs=layer)\n",
    "        model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer=\"adam\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnimeDiscriminatorFactory(object):\n",
    "    \"\"\"\n",
    "        Discriminator Factory Class that creates the model described here:\n",
    "        https://arxiv.org/pdf/1708.05509.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "            Returns a Model described here: https://arxiv.org/pdf/1708.05509.pdf\n",
    "            Args:\n",
    "                input_same: A 3 length tuple describing (width, height, channel)\n",
    "            Output:\n",
    "                Keras Model\n",
    "        \"\"\"\n",
    "        RESIDUAL_BLOCKS_PER_LAYER = 2\n",
    "        LEAKY_RELU_ALPHA = 0.2\n",
    "        MODULES = 5\n",
    "\n",
    "        def intermediate_layer(layer, filters, kernel_size):\n",
    "            \"\"\"\n",
    "                Create the intermediate layers between residual layers.\n",
    "                Args:\n",
    "                    layer:       Keras layer\n",
    "                    filters:     output size as an integer\n",
    "                    kernel_size: length 2 tuple\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            layer = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                           strides=(2, 2), padding=\"same\")(layer)\n",
    "            layer = LeakyReLU(alpha=LEAKY_RELU_ALPHA)(layer)\n",
    "            return layer\n",
    "\n",
    "        def initial_layer(input_layer):\n",
    "            \"\"\"\n",
    "                Facade for intermediate_layer for the first layer of the network.\n",
    "                Args:\n",
    "                    input_layer: Keras Input Layer\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            INITIAL_LAYER_FILTER = 32\n",
    "            INITIAL_KERNEL_SIZE = (4, 4)\n",
    "            return intermediate_layer(input_layer, INITIAL_LAYER_FILTER, INITIAL_KERNEL_SIZE)\n",
    "\n",
    "        def residual_block(layer, filters):\n",
    "            \"\"\"\n",
    "                Residual Block consisting of\n",
    "                    Conv2D -> LeakyReLU -> Conv2D -> LeakyReLU -> Residual Addition\n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            shortcut = layer\n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = LeakyReLU(alpha=LEAKY_RELU_ALPHA)(layer)\n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=(1, 1), padding=\"same\")(layer)\n",
    "\n",
    "            layer = Add()([layer, shortcut])\n",
    "            layer = LeakyReLU(alpha=LEAKY_RELU_ALPHA)(layer)\n",
    "            return layer\n",
    "\n",
    "        def residual_layer(layer, number, filters):\n",
    "            \"\"\"\n",
    "                Facade for residual block.\n",
    "                Creates Residual layer with specified number of residual blocks\n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of residual blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = residual_block(layer, filters)\n",
    "            return layer\n",
    "\n",
    "        # NOTE: notation kxnysz\n",
    "        # - k specifies that the convolution layer has kernel_size x\n",
    "        # - n specifies that the convolution layer has y feature maps\n",
    "        # - s specifies that the convolution layer has stride z\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        filters = 32\n",
    "        # initial layer k4n32s2\n",
    "        layer = initial_layer(inputs)\n",
    "        for i in range(MODULES):\n",
    "            layer = residual_layer(layer, RESIDUAL_BLOCKS_PER_LAYER, filters)\n",
    "            filters *= 2\n",
    "\n",
    "            intermediate_kernel_size = (3, 3)\n",
    "            if i < 2:\n",
    "                intermediate_kernel_size = (4, 4)\n",
    "            layer = intermediate_layer(\n",
    "                layer, filters, intermediate_kernel_size)\n",
    "\n",
    "        outputs = Dense(1, activation=\"sigmoid\")(layer)\n",
    "        \n",
    "        reshaped_output = Reshape((1,))(outputs)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=reshaped_output)\n",
    "        model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer=\"adam\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '../../../Downloads/faces/'\n",
    "valid_data_dir = '../../../Downloads/faces/real/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting layer built\n",
      "residual layer built\n",
      "sub-pixel layer built\n",
      "final layer built\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 16384)         2113536     input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, 16384)         65536       dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 16384)         0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)              (None, 16, 16, 64)    0           activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_65 (Conv2DTrans (None, 16, 16, 64)    36928       reshape_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_65[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 16, 16, 64)    0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_66 (Conv2DTrans (None, 16, 16, 64)    36928       activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_66[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_75 (Add)                     (None, 16, 16, 64)    0           batch_normalization_75[0][0]     \n",
      "                                                                   reshape_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_67 (Conv2DTrans (None, 16, 16, 64)    36928       add_75[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_67[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 16, 16, 64)    0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_68 (Conv2DTrans (None, 16, 16, 64)    36928       activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_68[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_76 (Add)                     (None, 16, 16, 64)    0           batch_normalization_77[0][0]     \n",
      "                                                                   add_75[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_69 (Conv2DTrans (None, 16, 16, 64)    36928       add_76[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_69[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 16, 16, 64)    0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_70 (Conv2DTrans (None, 16, 16, 64)    36928       activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_70[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_77 (Add)                     (None, 16, 16, 64)    0           batch_normalization_79[0][0]     \n",
      "                                                                   add_76[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_71 (Conv2DTrans (None, 16, 16, 64)    36928       add_77[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_71[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 16, 16, 64)    0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_72 (Conv2DTrans (None, 16, 16, 64)    36928       activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_72[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_78 (Add)                     (None, 16, 16, 64)    0           batch_normalization_81[0][0]     \n",
      "                                                                   add_77[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_73 (Conv2DTrans (None, 16, 16, 64)    36928       add_78[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_73[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 16, 16, 64)    0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_74 (Conv2DTrans (None, 16, 16, 64)    36928       activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_74[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_79 (Add)                     (None, 16, 16, 64)    0           batch_normalization_83[0][0]     \n",
      "                                                                   add_78[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_75 (Conv2DTrans (None, 16, 16, 64)    36928       add_79[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_75[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 16, 16, 64)    0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_76 (Conv2DTrans (None, 16, 16, 64)    36928       activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_76[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_80 (Add)                     (None, 16, 16, 64)    0           batch_normalization_85[0][0]     \n",
      "                                                                   add_79[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_77 (Conv2DTrans (None, 16, 16, 64)    36928       add_80[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_77[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 16, 16, 64)    0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_78 (Conv2DTrans (None, 16, 16, 64)    36928       activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_78[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_81 (Add)                     (None, 16, 16, 64)    0           batch_normalization_87[0][0]     \n",
      "                                                                   add_80[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_79 (Conv2DTrans (None, 16, 16, 64)    36928       add_81[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_79[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 16, 16, 64)    0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_80 (Conv2DTrans (None, 16, 16, 64)    36928       activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_80[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_82 (Add)                     (None, 16, 16, 64)    0           batch_normalization_89[0][0]     \n",
      "                                                                   add_81[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_81 (Conv2DTrans (None, 16, 16, 64)    36928       add_82[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_81[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 16, 16, 64)    0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_82 (Conv2DTrans (None, 16, 16, 64)    36928       activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_82[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_83 (Add)                     (None, 16, 16, 64)    0           batch_normalization_91[0][0]     \n",
      "                                                                   add_82[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_83 (Conv2DTrans (None, 16, 16, 64)    36928       add_83[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_83[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 16, 16, 64)    0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_84 (Conv2DTrans (None, 16, 16, 64)    36928       activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_84[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_84 (Add)                     (None, 16, 16, 64)    0           batch_normalization_93[0][0]     \n",
      "                                                                   add_83[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_85 (Conv2DTrans (None, 16, 16, 64)    36928       add_84[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_85[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 16, 16, 64)    0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_86 (Conv2DTrans (None, 16, 16, 64)    36928       activation_54[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_86[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_85 (Add)                     (None, 16, 16, 64)    0           batch_normalization_95[0][0]     \n",
      "                                                                   add_84[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_87 (Conv2DTrans (None, 16, 16, 64)    36928       add_85[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_87[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, 16, 16, 64)    0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_88 (Conv2DTrans (None, 16, 16, 64)    36928       activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_88[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_86 (Add)                     (None, 16, 16, 64)    0           batch_normalization_97[0][0]     \n",
      "                                                                   add_85[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_89 (Conv2DTrans (None, 16, 16, 64)    36928       add_86[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_89[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, 16, 16, 64)    0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_90 (Conv2DTrans (None, 16, 16, 64)    36928       activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 16, 16, 64)    256         conv2d_transpose_90[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_87 (Add)                     (None, 16, 16, 64)    0           batch_normalization_99[0][0]     \n",
      "                                                                   add_86[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_91 (Conv2DTrans (None, 16, 16, 64)    36928       add_87[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_91[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, 16, 16, 64)    0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_92 (Conv2DTrans (None, 16, 16, 64)    36928       activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_92[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_88 (Add)                     (None, 16, 16, 64)    0           batch_normalization_101[0][0]    \n",
      "                                                                   add_87[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_93 (Conv2DTrans (None, 16, 16, 64)    36928       add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_93[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, 16, 16, 64)    0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_94 (Conv2DTrans (None, 16, 16, 64)    36928       activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_94[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_89 (Add)                     (None, 16, 16, 64)    0           batch_normalization_103[0][0]    \n",
      "                                                                   add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_95 (Conv2DTrans (None, 16, 16, 64)    36928       add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_95[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, 16, 16, 64)    0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_96 (Conv2DTrans (None, 16, 16, 64)    36928       activation_59[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, 16, 16, 64)    256         conv2d_transpose_96[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "add_90 (Add)                     (None, 16, 16, 64)    0           batch_normalization_105[0][0]    \n",
      "                                                                   add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, 16, 16, 64)    256         add_90[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, 16, 16, 64)    0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "add_91 (Add)                     (None, 16, 16, 64)    0           activation_60[0][0]              \n",
      "                                                                   reshape_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 16, 16, 256)   147712      add_91[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "subpixel_5 (Subpixel)            (None, 32, 32, 256)   2360320     conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, 32, 32, 256)   1024        subpixel_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, 32, 32, 256)   0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, 32, 32, 256)   590080      activation_61[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "subpixel_6 (Subpixel)            (None, 64, 64, 256)   2360320     conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, 64, 64, 256)   1024        subpixel_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, 64, 64, 256)   0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 64, 64, 3)     62211       activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, 64, 64, 3)     0           conv2d_113[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 8,891,907\n",
      "Trainable params: 8,853,891\n",
      "Non-trainable params: 38,016\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generator1 = keras_generator()\n",
    "# generator2 = keras_generator()\n",
    "# generator3 = keras_generator()\n",
    "\n",
    "generator = AnimeGeneratorFactory().build([input_dim])\n",
    "generator.summary()\n",
    "\n",
    "ganInput = Input((input_dim,))\n",
    "\n",
    "# x1 = generator1(ganInput)\n",
    "# x2 = generator2(ganInput)\n",
    "# x3 = generator3(ganInput)\n",
    "\n",
    "x = generator(ganInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 32, 32, 32)    1568        input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_105 (LeakyReLU)      (None, 32, 32, 32)    0           conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 32, 32, 32)    9248        leaky_re_lu_105[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_106 (LeakyReLU)      (None, 32, 32, 32)    0           conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 32, 32, 32)    9248        leaky_re_lu_106[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_92 (Add)                     (None, 32, 32, 32)    0           conv2d_116[0][0]                 \n",
      "                                                                   leaky_re_lu_105[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_107 (LeakyReLU)      (None, 32, 32, 32)    0           add_92[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 32, 32, 32)    9248        leaky_re_lu_107[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_108 (LeakyReLU)      (None, 32, 32, 32)    0           conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 32, 32, 32)    9248        leaky_re_lu_108[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_93 (Add)                     (None, 32, 32, 32)    0           conv2d_118[0][0]                 \n",
      "                                                                   leaky_re_lu_107[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_109 (LeakyReLU)      (None, 32, 32, 32)    0           add_93[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, 16, 16, 64)    32832       leaky_re_lu_109[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_110 (LeakyReLU)      (None, 16, 16, 64)    0           conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, 16, 16, 64)    36928       leaky_re_lu_110[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_111 (LeakyReLU)      (None, 16, 16, 64)    0           conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 16, 16, 64)    36928       leaky_re_lu_111[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_94 (Add)                     (None, 16, 16, 64)    0           conv2d_121[0][0]                 \n",
      "                                                                   leaky_re_lu_110[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_112 (LeakyReLU)      (None, 16, 16, 64)    0           add_94[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 16, 16, 64)    36928       leaky_re_lu_112[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_113 (LeakyReLU)      (None, 16, 16, 64)    0           conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 16, 16, 64)    36928       leaky_re_lu_113[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_95 (Add)                     (None, 16, 16, 64)    0           conv2d_123[0][0]                 \n",
      "                                                                   leaky_re_lu_112[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_114 (LeakyReLU)      (None, 16, 16, 64)    0           add_95[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 8, 8, 128)     131200      leaky_re_lu_114[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)      (None, 8, 8, 128)     0           conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 8, 8, 128)     147584      leaky_re_lu_115[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_116 (LeakyReLU)      (None, 8, 8, 128)     0           conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 8, 8, 128)     147584      leaky_re_lu_116[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_96 (Add)                     (None, 8, 8, 128)     0           conv2d_126[0][0]                 \n",
      "                                                                   leaky_re_lu_115[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_117 (LeakyReLU)      (None, 8, 8, 128)     0           add_96[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 8, 8, 128)     147584      leaky_re_lu_117[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_118 (LeakyReLU)      (None, 8, 8, 128)     0           conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 8, 8, 128)     147584      leaky_re_lu_118[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_97 (Add)                     (None, 8, 8, 128)     0           conv2d_128[0][0]                 \n",
      "                                                                   leaky_re_lu_117[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_119 (LeakyReLU)      (None, 8, 8, 128)     0           add_97[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 4, 4, 256)     295168      leaky_re_lu_119[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_120 (LeakyReLU)      (None, 4, 4, 256)     0           conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 4, 4, 256)     590080      leaky_re_lu_120[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_121 (LeakyReLU)      (None, 4, 4, 256)     0           conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 4, 4, 256)     590080      leaky_re_lu_121[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_98 (Add)                     (None, 4, 4, 256)     0           conv2d_131[0][0]                 \n",
      "                                                                   leaky_re_lu_120[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_122 (LeakyReLU)      (None, 4, 4, 256)     0           add_98[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 4, 4, 256)     590080      leaky_re_lu_122[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_123 (LeakyReLU)      (None, 4, 4, 256)     0           conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 4, 4, 256)     590080      leaky_re_lu_123[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_99 (Add)                     (None, 4, 4, 256)     0           conv2d_133[0][0]                 \n",
      "                                                                   leaky_re_lu_122[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_124 (LeakyReLU)      (None, 4, 4, 256)     0           add_99[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 2, 2, 512)     1180160     leaky_re_lu_124[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_125 (LeakyReLU)      (None, 2, 2, 512)     0           conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 2, 2, 512)     2359808     leaky_re_lu_125[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_126 (LeakyReLU)      (None, 2, 2, 512)     0           conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 2, 2, 512)     2359808     leaky_re_lu_126[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_100 (Add)                    (None, 2, 2, 512)     0           conv2d_136[0][0]                 \n",
      "                                                                   leaky_re_lu_125[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_127 (LeakyReLU)      (None, 2, 2, 512)     0           add_100[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 2, 2, 512)     2359808     leaky_re_lu_127[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_128 (LeakyReLU)      (None, 2, 2, 512)     0           conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 2, 2, 512)     2359808     leaky_re_lu_128[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_101 (Add)                    (None, 2, 2, 512)     0           conv2d_138[0][0]                 \n",
      "                                                                   leaky_re_lu_127[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_129 (LeakyReLU)      (None, 2, 2, 512)     0           add_101[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 1, 1, 1024)    4719616     leaky_re_lu_129[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_130 (LeakyReLU)      (None, 1, 1, 1024)    0           conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1, 1, 1)       1025        leaky_re_lu_130[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)              (None, 1)             0           dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 18,936,161\n",
      "Trainable params: 18,936,161\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = AnimeDiscriminatorFactory().build((64, 64, 3))\n",
    "discriminator.summary()\n",
    "# d_input = keras.layers.concatenate([x1, x2, x3], axis=-1)\n",
    "# d_input = Reshape((96, 96, 3))(d_input)\n",
    "# generator = Model(inputs=ganInput, outputs=d_input)\n",
    "# ganOutput = discriminator(d_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganOutput = discriminator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dLosses = []\n",
    "gLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the loss from each batch\n",
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dLosses, label='Discriminitive loss')\n",
    "    # plt.plot(gLosses, label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('./collected_data/gan_loss_epoch_%d.png' % epoch)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a wall of generated MNIST images\n",
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, input_dim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 64, 64, 3)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./collected_data/gan_generated_image_epoch_%d.png' % epoch)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the generator and discriminator networks (and weights) for later use\n",
    "def saveModels(epoch):\n",
    "    generator.save('./collected_models/gan_generator1_epoch_%d.h5' % epoch)\n",
    "    # generator1.save('./collected_models/gan_generator1_epoch_%d.h5' % epoch)\n",
    "    # generator2.save('./collected_models/gan_generator2_epoch_%d.h5' % epoch)\n",
    "    # generator3.save('./collected_models/gan_generator3_epoch_%d.h5' % epoch)\n",
    "    discriminator.save('./collected_models/gan_discriminator_epoch_%d.h5' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = int(images_train.shape[0] / batchSize)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', batchSize)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    valid_datagen = ImageDataGenerator(rescale = (1./255))\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='binary')\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        dloss = 0\n",
    "        gloss = 0\n",
    "        for batch, label in train_generator:\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, input_dim])\n",
    "            #imageBatch = images_train[np.random.randint(0, images_train.shape[0], size=batchSize)]\n",
    "\n",
    "            # Generate fake images\n",
    "            generatedImages = generator.predict(noise)\n",
    "            # print(np.shape(imageBatch), np.shape(generatedImages))\n",
    "            X = np.concatenate([batch, generatedImages])\n",
    "            # print(X.shape)\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            yDis = np.zeros(2*batchSize)\n",
    "            # One-sided label smoothing\n",
    "            yDis[:batchSize] = 0.9\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            (dloss, dAcc) = discriminator.train_on_batch(X, yDis)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, input_dim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "            # print('-'*5, 'Batch %d/%d done' % ((b + 1), batchCount))\n",
    "\n",
    "        # Store loss of most recent batch from this epoch\n",
    "        dLosses.append(dloss)\n",
    "        # gLosses.append(gloss)\n",
    "\n",
    "        plotGeneratedImages(e)\n",
    "        if e == 1 or e % 20 == 0:\n",
    "            saveModels(e)\n",
    "\n",
    "    # Plot losses from every epoch\n",
    "    plotLoss(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1\n",
      "Batch size: 1\n",
      "Batches per epoch: 50000\n",
      "Found 15 images belonging to 1 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "--------------- Epoch 1 ---------------\n",
      "generated\n",
      "mixed\n",
      "done\n",
      "generated\n",
      "mixed\n",
      "done\n",
      "generated\n",
      "mixed\n",
      "done\n",
      "generated\n",
      "mixed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-51f64ded82a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-596eef9a191a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batchSize)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0myGen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mgloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myGen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# print('-'*5, 'Batch %d/%d done' % ((b + 1), batchCount))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
