{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Conv3D, MaxPool3D, Conv2D, MaxPool2D, Flatten\n",
    "from keras.layers import Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.models import Input, Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_images_from_files_to_list(root, files, list, data_cb=None):\n",
    "    if files:\n",
    "        def identity(v):\n",
    "            return v\n",
    "\n",
    "        if data_cb is None:\n",
    "            data_cb = identity\n",
    "\n",
    "        for index, file in enumerate(files):\n",
    "            image = cv2.imread(os.path.join(root, file))\n",
    "\n",
    "            if image is not None:\n",
    "                list.append(data_cb(image))\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2it [00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r3it [00:01,  2.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4it [00:02,  1.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5it [00:02,  1.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6it [00:03,  1.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r7it [00:03,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8it [00:04,  1.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r9it [00:04,  1.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r10it [00:05,  1.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r11it [00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r12it [00:06,  1.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r13it [00:07,  1.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r14it [00:08,  1.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-789029719329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_directories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./danbooru-faces\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0madd_images_from_files_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-3086cae4d3d8>\u001b[0m in \u001b[0;36madd_images_from_files_to_list\u001b[0;34m(root, files, list, data_cb)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "for root, sub_directories, files in tqdm(os.walk(\"./danbooru-faces\")):\n",
    "    add_images_from_files_to_list(root, files, images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = np.array(images_train)\n",
    "# images_train = images_train.reshape((images_train.shape[0],\n",
    "#                       images_train.shape[3],\n",
    "#                       images_train.shape[1],\n",
    "#                       images_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14901, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.4\n",
    "depth = 256\n",
    "dim = 30\n",
    "input_dim = 128\n",
    "batch_size = 128\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_generator():\n",
    "    g = Sequential()\n",
    "    # In: 100\n",
    "    # Out: dim x dim x depth\n",
    "    g.add(Dense(dim * dim * depth, input_dim=input_dim))\n",
    "    g.add(BatchNormalization(momentum=0.9))\n",
    "    g.add(Activation('relu'))\n",
    "    g.add(Reshape((dim, dim, depth)))\n",
    "    g.add(Dropout(dropout))\n",
    "    # In: dim x dim x depth\n",
    "    # Out: 2*dim x 2*dim x depth/2\n",
    "    g.add(UpSampling2D())\n",
    "    g.add(Conv2DTranspose(int(depth / 2), 5, padding='same'))\n",
    "    g.add(BatchNormalization(momentum=0.9))\n",
    "    g.add(Activation('relu'))\n",
    "    g.add(UpSampling2D())\n",
    "    g.add(Conv2DTranspose(int(depth / 4), 5, padding='same'))\n",
    "    g.add(BatchNormalization(momentum=0.9))\n",
    "    g.add(Activation('relu'))\n",
    "    # In: dim x dim x depth\n",
    "    # Out: 4*dim x 4*dim x depth/4\n",
    "    g.add(UpSampling2D())\n",
    "    g.add(Conv2DTranspose(int(depth / 8), 5, padding='same'))\n",
    "    g.add(BatchNormalization(momentum=0.9))\n",
    "    g.add(Activation('relu'))\n",
    "    g.add(UpSampling2D())\n",
    "    g.add(Conv2DTranspose(int(depth / 16), 5, padding='same'))\n",
    "    g.add(BatchNormalization(momentum=0.9))\n",
    "    g.add(Activation('relu'))\n",
    "    # Out: 480 x 480 x 1 grayscale image [0.0,1.0] per pix\n",
    "    g.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "    g.add(Activation('relu'))\n",
    "    \n",
    "    g.add(Reshape((480 * 480,)))\n",
    "    \n",
    "    # Out: 96 x 96 x 1 grayscale image\n",
    "    g.add(Dense(96 * 96))\n",
    "    g.add(Reshape((96, 96)))\n",
    "    g.add(Activation('tanh'))\n",
    "    g.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    g.summary()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_discriminator():\n",
    "    \"\"\"\n",
    "        Translation of tutorial into Keras.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=images_train.shape[1:])\n",
    "    layer = Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\")(inputs)\n",
    "    layer = MaxPool2D()(layer)\n",
    "    layer = Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\")(layer)\n",
    "    layer = MaxPool2D()(layer)\n",
    "\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=1024, activation=\"relu\")(layer)\n",
    "    layer = Dense(units=128, activation=\"relu\")(layer)\n",
    "    outputs = Dense(units=1, activation=\"sigmoid\")(layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_7 (Dense)              (None, 230400)            29721600  \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 230400)            921600    \n_________________________________________________________________\nactivation_22 (Activation)   (None, 230400)            0         \n_________________________________________________________________\nreshape_10 (Reshape)         (None, 30, 30, 256)       0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 30, 30, 256)       0         \n_________________________________________________________________\nup_sampling2d_13 (UpSampling (None, 60, 60, 256)       0         \n_________________________________________________________________\nconv2d_transpose_16 (Conv2DT (None, 60, 60, 128)       819328    \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 60, 60, 128)       512       \n_________________________________________________________________\nactivation_23 (Activation)   (None, 60, 60, 128)       0         \n_________________________________________________________________\nup_sampling2d_14 (UpSampling (None, 120, 120, 128)     0         \n_________________________________________________________________\nconv2d_transpose_17 (Conv2DT (None, 120, 120, 64)      204864    \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 120, 120, 64)      256       \n_________________________________________________________________\nactivation_24 (Activation)   (None, 120, 120, 64)      0         \n_________________________________________________________________\nup_sampling2d_15 (UpSampling (None, 240, 240, 64)      0         \n_________________________________________________________________\nconv2d_transpose_18 (Conv2DT (None, 240, 240, 32)      51232     \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 240, 240, 32)      128       \n_________________________________________________________________\nactivation_25 (Activation)   (None, 240, 240, 32)      0         \n_________________________________________________________________\nup_sampling2d_16 (UpSampling (None, 480, 480, 32)      0         \n_________________________________________________________________\nconv2d_transpose_19 (Conv2DT (None, 480, 480, 16)      12816     \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 480, 480, 16)      64        \n_________________________________________________________________\nactivation_26 (Activation)   (None, 480, 480, 16)      0         \n_________________________________________________________________\nconv2d_transpose_20 (Conv2DT (None, 480, 480, 1)       401       \n_________________________________________________________________\nactivation_27 (Activation)   (None, 480, 480, 1)       0         \n_________________________________________________________________\nreshape_11 (Reshape)         (None, 230400)            0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 9216)              2123375616\n_________________________________________________________________\nreshape_12 (Reshape)         (None, 96, 96)            0         \n_________________________________________________________________\nactivation_28 (Activation)   (None, 96, 96)            0         \n=================================================================\nTotal params: 2,155,108,417\nTrainable params: 2,154,647,137\nNon-trainable params: 461,280\n_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_9 (Dense)              (None, 230400)            29721600  \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 230400)            921600    \n_________________________________________________________________\nactivation_29 (Activation)   (None, 230400)            0         \n_________________________________________________________________\nreshape_13 (Reshape)         (None, 30, 30, 256)       0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 30, 30, 256)       0         \n_________________________________________________________________\nup_sampling2d_17 (UpSampling (None, 60, 60, 256)       0         \n_________________________________________________________________\nconv2d_transpose_21 (Conv2DT (None, 60, 60, 128)       819328    \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 60, 60, 128)       512       \n_________________________________________________________________\nactivation_30 (Activation)   (None, 60, 60, 128)       0         \n_________________________________________________________________\nup_sampling2d_18 (UpSampling (None, 120, 120, 128)     0         \n_________________________________________________________________\nconv2d_transpose_22 (Conv2DT (None, 120, 120, 64)      204864    \n_________________________________________________________________\nbatch_normalization_23 (Batc (None, 120, 120, 64)      256       \n_________________________________________________________________\nactivation_31 (Activation)   (None, 120, 120, 64)      0         \n_________________________________________________________________\nup_sampling2d_19 (UpSampling (None, 240, 240, 64)      0         \n_________________________________________________________________\nconv2d_transpose_23 (Conv2DT (None, 240, 240, 32)      51232     \n_________________________________________________________________\nbatch_normalization_24 (Batc (None, 240, 240, 32)      128       \n_________________________________________________________________\nactivation_32 (Activation)   (None, 240, 240, 32)      0         \n_________________________________________________________________\nup_sampling2d_20 (UpSampling (None, 480, 480, 32)      0         \n_________________________________________________________________\nconv2d_transpose_24 (Conv2DT (None, 480, 480, 16)      12816     \n_________________________________________________________________\nbatch_normalization_25 (Batc (None, 480, 480, 16)      64        \n_________________________________________________________________\nactivation_33 (Activation)   (None, 480, 480, 16)      0         \n_________________________________________________________________\nconv2d_transpose_25 (Conv2DT (None, 480, 480, 1)       401       \n_________________________________________________________________\nactivation_34 (Activation)   (None, 480, 480, 1)       0         \n_________________________________________________________________\nreshape_14 (Reshape)         (None, 230400)            0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 9216)              2123375616\n_________________________________________________________________\nreshape_15 (Reshape)         (None, 96, 96)            0         \n_________________________________________________________________\nactivation_35 (Activation)   (None, 96, 96)            0         \n=================================================================\nTotal params: 2,155,108,417\nTrainable params: 2,154,647,137\nNon-trainable params: 461,280\n_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_11 (Dense)             (None, 230400)            29721600  \n_________________________________________________________________\nbatch_normalization_26 (Batc (None, 230400)            921600    \n_________________________________________________________________\nactivation_36 (Activation)   (None, 230400)            0         \n_________________________________________________________________\nreshape_16 (Reshape)         (None, 30, 30, 256)       0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 30, 30, 256)       0         \n_________________________________________________________________\nup_sampling2d_21 (UpSampling (None, 60, 60, 256)       0         \n_________________________________________________________________\nconv2d_transpose_26 (Conv2DT (None, 60, 60, 128)       819328    \n_________________________________________________________________\nbatch_normalization_27 (Batc (None, 60, 60, 128)       512       \n_________________________________________________________________\nactivation_37 (Activation)   (None, 60, 60, 128)       0         \n_________________________________________________________________\nup_sampling2d_22 (UpSampling (None, 120, 120, 128)     0         \n_________________________________________________________________\nconv2d_transpose_27 (Conv2DT (None, 120, 120, 64)      204864    \n_________________________________________________________________\nbatch_normalization_28 (Batc (None, 120, 120, 64)      256       \n_________________________________________________________________\nactivation_38 (Activation)   (None, 120, 120, 64)      0         \n_________________________________________________________________\nup_sampling2d_23 (UpSampling (None, 240, 240, 64)      0         \n_________________________________________________________________\nconv2d_transpose_28 (Conv2DT (None, 240, 240, 32)      51232     \n_________________________________________________________________\nbatch_normalization_29 (Batc (None, 240, 240, 32)      128       \n_________________________________________________________________\nactivation_39 (Activation)   (None, 240, 240, 32)      0         \n_________________________________________________________________\nup_sampling2d_24 (UpSampling (None, 480, 480, 32)      0         \n_________________________________________________________________\nconv2d_transpose_29 (Conv2DT (None, 480, 480, 16)      12816     \n_________________________________________________________________\nbatch_normalization_30 (Batc (None, 480, 480, 16)      64        \n_________________________________________________________________\nactivation_40 (Activation)   (None, 480, 480, 16)      0         \n_________________________________________________________________\nconv2d_transpose_30 (Conv2DT (None, 480, 480, 1)       401       \n_________________________________________________________________\nactivation_41 (Activation)   (None, 480, 480, 1)       0         \n_________________________________________________________________\nreshape_17 (Reshape)         (None, 230400)            0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 9216)              2123375616\n_________________________________________________________________\nreshape_18 (Reshape)         (None, 96, 96)            0         \n_________________________________________________________________\nactivation_42 (Activation)   (None, 96, 96)            0         \n=================================================================\nTotal params: 2,155,108,417\nTrainable params: 2,154,647,137\nNon-trainable params: 461,280\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator1 = keras_generator()\n",
    "generator2 = keras_generator()\n",
    "generator3 = keras_generator()\n",
    "\n",
    "ganInput = Input((input_dim,))\n",
    "\n",
    "x1 = generator1(ganInput)\n",
    "x2 = generator2(ganInput)\n",
    "x3 = generator3(ganInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         (None, 96, 96, 3)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 92, 92, 32)        2432      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 46, 46, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 42, 42, 64)        51264     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 21, 21, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 28224)             0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 1024)              28902400  \n_________________________________________________________________\ndense_14 (Dense)             (None, 128)               131200    \n_________________________________________________________________\ndense_15 (Dense)             (None, 1)                 129       \n=================================================================\nTotal params: 29,087,425\nTrainable params: 29,087,425\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras_discriminator()\n",
    "d_input = keras.layers.concatenate([x1, x2, x3], axis=-1)\n",
    "d_input = Reshape((96, 96, 3))(d_input)\n",
    "generator = Model(inputs=ganInput, outputs=d_input)\n",
    "ganOutput = discriminator(d_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dLosses = []\n",
    "gLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss from each batch\n",
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dLosses, label='Discriminitive loss')\n",
    "    plt.plot(gLosses, label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('./collected_data/gan_loss_epoch_%d.png' % epoch)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wall of generated MNIST images\n",
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, input_dim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./collected_data/gan_generated_image_epoch_%d.png' % epoch)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generator and discriminator networks (and weights) for later use\n",
    "def saveModels(epoch):\n",
    "    generator1.save('./collected_models/gan_generator1_epoch_%d.h5' % epoch)\n",
    "    generator2.save('./collected_models/gan_generator2_epoch_%d.h5' % epoch)\n",
    "    generator3.save('./collected_models/gan_generator3_epoch_%d.h5' % epoch)\n",
    "    discriminator.save('./collected_models/gan_discriminator_epoch_%d.h5' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = int(images_train.shape[0] / batchSize)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', batchSize)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in range(batchCount):\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, input_dim])\n",
    "            imageBatch = images_train[np.random.randint(0, images_train.shape[0], size=batchSize)]\n",
    "\n",
    "            # Generate fake MNIST images\n",
    "            generatedImages = generator.predict(noise)\n",
    "            # print np.shape(imageBatch), np.shape(generatedImages)\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            yDis = np.zeros(2*batchSize)\n",
    "            # One-sided label smoothing\n",
    "            yDis[:batchSize] = 0.9\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yDis)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, input_dim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "\n",
    "        # Store loss of most recent batch from this epoch\n",
    "        dLosses.append(dloss)\n",
    "        gLosses.append(gloss)\n",
    "\n",
    "        if e == 1 or e % 20 == 0:\n",
    "            plotGeneratedImages(e)\n",
    "            saveModels(e)\n",
    "\n",
    "    # Plot losses from every epoch\n",
    "    plotLoss(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 200\nBatch size: 128\nBatches per epoch: 116\n--------------- Epoch 1 ---------------\n"
     ]
    }
   ],
   "source": [
    "train(epochs, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
