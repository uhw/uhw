{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf         \n",
    "from keras.layers import BatchNormalization, LeakyReLU, Add\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.models import Input, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "import os\n",
    "\n",
    "if not os.path.isdir(\"./collected_data\"):\n",
    "    os.makedirs(\"./collected_data\")\n",
    "    \n",
    "if not os.path.isdir(\"./collected_models\"):\n",
    "    os.makedirs(\"./collected_models\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as IM\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_image = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_images_from_files_to_list(root, files, list, next_index, data_cb=None):\n",
    "    if files and next_index < num_image:\n",
    "        def identity(v):\n",
    "            return v\n",
    "\n",
    "        if data_cb is None:\n",
    "            data_cb = identity\n",
    "\n",
    "        for index, file in enumerate(files):\n",
    "            if file.endswith('.png'):\n",
    "                image = IM.load_img(os.path.join(root, file))\n",
    "                if image is not None and next_index < num_image:\n",
    "                    list[next_index] = data_cb(image.reshape((64, 64, 3)))\n",
    "                    next_index += 1\n",
    "                # list.append(data_cb(image[:, :, 0]))\n",
    "    return next_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_train = np.empty((num_image, 64, 64, 3))\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, sub_directories, files in os.walk(\"\"):\n",
    "    if i < num_image:\n",
    "        print(i)\n",
    "        i = add_images_from_files_to_list(root, files, images_train, i)\n",
    "\n",
    "# plt.subplot(96, 96)\n",
    "# plt.imshow(images_train[20], interpolation='nearest', cmap='gray_r')\n",
    "# plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('./collected_data/gan_generated_image_epoch_%d.png' % 999)\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images_train = np.array(images_train)\n",
    "# images_train = images_train.reshape((*images_train.shape, 1))\n",
    "# images_train = images_train[:, :, :, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout = 0.4\n",
    "depth = 256\n",
    "dim = 8\n",
    "input_dim = 128\n",
    "batch_size = 1\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subpixel(Conv2D):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 r,\n",
    "                 padding='same',\n",
    "                 data_format=None,\n",
    "                 strides=(1,1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Subpixel, self).__init__(\n",
    "            filters=r*r*filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _phase_shift(self, I):\n",
    "        r = self.r\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        bsize = K.shape(I)[0] # Handling Dimension(None) type for undefined batch dim\n",
    "        X = K.reshape(I, [bsize, a, b, int(c/(r*r)),r, r]) # bsize, a, b, c/(r*r), r, r\n",
    "        X = K.permute_dimensions(X, (0, 1, 2, 5, 4, 3))  # bsize, a, b, r, r, c/(r*r)\n",
    "        #Keras backend does not support tf.split, so in future versions this could be nicer\n",
    "        X = [X[:,i,:,:,:,:] for i in range(a)] # a, [bsize, b, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, b, a*r, r, c/(r*r)\n",
    "        X = [X[:,i,:,:,:] for i in range(b)] # b, [bsize, r, r, c/(r*r)\n",
    "        X = K.concatenate(X, 2)  # bsize, a*r, b*r, c/(r*r)\n",
    "        return X\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self._phase_shift(super(Subpixel, self).call(inputs))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        unshifted = super(Subpixel, self).compute_output_shape(input_shape)\n",
    "        return (unshifted[0], int(self.r*unshifted[1]), int(self.r*unshifted[2]), int(unshifted[3]/(self.r*self.r)))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        config.pop('dilation_rate')\n",
    "        config['filters']/=int(self.r*self.r)\n",
    "        config['r'] = self.r\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnimeGeneratorFactory():\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "            Returns a generator Model described here: https://arxiv.org/pdf/1708.05509.pdf\n",
    "            \n",
    "            Args:\n",
    "                input_same: A 3 length tuple describing (width, height, channel)\n",
    "                \n",
    "            Output:\n",
    "                Keras Model\n",
    "        \"\"\"\n",
    "        MOMENTUM = 0.9\n",
    "        DIM = 16\n",
    "        DEPTH = 64\n",
    "        NUM_RESIDUAL = 16\n",
    "        NUM_SUBPIXEL = 2\n",
    "        FINAL_FILTERS = 3\n",
    "        #FINAL_FILTERS = 1\n",
    "        INITIAL_FILTERS = 64\n",
    "        def residual_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                Residual Block consisting of\n",
    "                    Conv2D -> Batch Normalization -> relu -> Conv2D -> Batch Normalization -> Residual Addition\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            shortcut = layer\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum=momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Conv2DTranspose(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = BatchNormalization(momentum=momentum)(layer)\n",
    "\n",
    "            layer = Add()([layer, shortcut])\n",
    "            return layer\n",
    "\n",
    "        def residual_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for residual block.\n",
    "                \n",
    "                Creates Residual layer with specified number of residual blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of residual blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = residual_block(layer, filters, momentum)\n",
    "            return layer\n",
    "\n",
    "        def subpixel_block(layer, filters, momentum):\n",
    "            \"\"\"\n",
    "                sub-pixel block consisting of\n",
    "                    Conv2D -> pixel shuffler x 2 -> Batch Normalization -> Relu\n",
    "                    \n",
    "                the code of subpixel layer is based on https://github.com/Tetrachrome/subpixel\n",
    "                    \n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "\n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = Subpixel(filters, (3, 3), 2)(layer)\n",
    "\n",
    "            layer = BatchNormalization(momentum=momentum)(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            return layer\n",
    "\n",
    "        def subpixel_layer(layer, number, filters, momentum):\n",
    "            \"\"\"\n",
    "                Facade for subpixel block.\n",
    "                \n",
    "                Creates subpixel layer with specified number of subpixel blocks\n",
    "                \n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of subpixel blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                    momentum: variable for batch normalization\n",
    "                \n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = subpixel_block(layer, filters, momentum)\n",
    "            return layer\n",
    "        inputs = Input(shape=input_shape)\n",
    "        filters = INITIAL_FILTERS\n",
    "        layer = Dense(DEPTH * DIM * DIM)(inputs)\n",
    "\n",
    "        layer = BatchNormalization(momentum=MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Reshape((DIM, DIM, DEPTH))(layer)\n",
    "        old = layer\n",
    "        print(\"starting layer built\")\n",
    "        # 16 residual layers\n",
    "        layer = residual_layer(layer, NUM_RESIDUAL, filters, MOMENTUM)\n",
    "\n",
    "        layer = BatchNormalization(momentum=MOMENTUM)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Add()([layer, old])\n",
    "\n",
    "        print(\"residual layer built\")\n",
    "\n",
    "        filters *= 4\n",
    "        # 3 sub-pixel layers\n",
    "        layer = subpixel_layer(layer, NUM_SUBPIXEL, filters, MOMENTUM)\n",
    "\n",
    "        print(\"sub-pixel layer built\")\n",
    "\n",
    "        layer = Conv2D(filters=FINAL_FILTERS, kernel_size=(9, 9), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = Activation('tanh')(layer)\n",
    "\n",
    "        print(\"final layer built\")\n",
    "        model = Model(inputs=inputs, outputs=layer)\n",
    "        model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer=\"adam\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnimeDiscriminatorFactory(object):\n",
    "    \"\"\"\n",
    "        Discriminator Factory Class that creates the model described here:\n",
    "        https://arxiv.org/pdf/1708.05509.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "            Returns a Model described here: https://arxiv.org/pdf/1708.05509.pdf\n",
    "            Args:\n",
    "                input_same: A 3 length tuple describing (width, height, channel)\n",
    "            Output:\n",
    "                Keras Model\n",
    "        \"\"\"\n",
    "        RESIDUAL_BLOCKS_PER_LAYER = 2\n",
    "        LEAKY_RELU_ALPHA = 0.2\n",
    "        MODULES = 5\n",
    "\n",
    "        def intermediate_layer(layer, filters, kernel_size):\n",
    "            \"\"\"\n",
    "                Create the intermediate layers between residual layers.\n",
    "                Args:\n",
    "                    layer:       Keras layer\n",
    "                    filters:     output size as an integer\n",
    "                    kernel_size: length 2 tuple\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            layer = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                           strides=(2, 2), padding=\"same\")(layer)\n",
    "            layer = LeakyReLU(alpha=LEAKY_RELU_ALPHA)(layer)\n",
    "            return layer\n",
    "\n",
    "        def initial_layer(input_layer):\n",
    "            \"\"\"\n",
    "                Facade for intermediate_layer for the first layer of the network.\n",
    "                Args:\n",
    "                    input_layer: Keras Input Layer\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            INITIAL_LAYER_FILTER = 32\n",
    "            INITIAL_KERNEL_SIZE = (4, 4)\n",
    "            return intermediate_layer(input_layer, INITIAL_LAYER_FILTER, INITIAL_KERNEL_SIZE)\n",
    "\n",
    "        def residual_block(layer, filters):\n",
    "            \"\"\"\n",
    "                Residual Block consisting of\n",
    "                    Conv2D -> LeakyReLU -> Conv2D -> LeakyReLU -> Residual Addition\n",
    "                Args:\n",
    "                    layer:   Keras Layer\n",
    "                    filters: output size as an integer\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            shortcut = layer\n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=(1, 1), padding=\"same\")(layer)\n",
    "            layer = LeakyReLU(alpha=LEAKY_RELU_ALPHA)(layer)\n",
    "            layer = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=(1, 1), padding=\"same\")(layer)\n",
    "\n",
    "            layer = Add()([layer, shortcut])\n",
    "            layer = LeakyReLU(alpha=LEAKY_RELU_ALPHA)(layer)\n",
    "            return layer\n",
    "\n",
    "        def residual_layer(layer, number, filters):\n",
    "            \"\"\"\n",
    "                Facade for residual block.\n",
    "                Creates Residual layer with specified number of residual blocks\n",
    "                Args:\n",
    "                    layer:   Keras layer\n",
    "                    number:  number of residual blocks in layer\n",
    "                    filters: output size as an integer\n",
    "                Returns:\n",
    "                    Keras layer\n",
    "            \"\"\"\n",
    "            for _ in range(number):\n",
    "                layer = residual_block(layer, filters)\n",
    "            return layer\n",
    "\n",
    "        # NOTE: notation kxnysz\n",
    "        # - k specifies that the convolution layer has kernel_size x\n",
    "        # - n specifies that the convolution layer has y feature maps\n",
    "        # - s specifies that the convolution layer has stride z\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        filters = 32\n",
    "        # initial layer k4n32s2\n",
    "        layer = initial_layer(inputs)\n",
    "        for i in range(MODULES):\n",
    "            layer = residual_layer(layer, RESIDUAL_BLOCKS_PER_LAYER, filters)\n",
    "            filters *= 2\n",
    "\n",
    "            intermediate_kernel_size = (3, 3)\n",
    "            if i < 2:\n",
    "                intermediate_kernel_size = (4, 4)\n",
    "            layer = intermediate_layer(\n",
    "                layer, filters, intermediate_kernel_size)\n",
    "\n",
    "        outputs = Dense(1, activation=\"sigmoid\")(layer)\n",
    "        \n",
    "        reshaped_output = Reshape((1,))(outputs)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=reshaped_output)\n",
    "        model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer=\"adam\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = '../dataset-download/faces/'\n",
    "valid_data_dir = '../dataset-download/faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting layer built\n",
      "residual layer built\n",
      "sub-pixel layer built\n",
      "final layer built\n"
     ]
    }
   ],
   "source": [
    "# generator1 = keras_generator()\n",
    "# generator2 = keras_generator()\n",
    "# generator3 = keras_generator()\n",
    "\n",
    "generator = AnimeGeneratorFactory().build([input_dim])\n",
    "# generator.summary()\n",
    "\n",
    "ganInput = Input((input_dim,))\n",
    "\n",
    "# x1 = generator1(ganInput)\n",
    "# x2 = generator2(ganInput)\n",
    "# x3 = generator3(ganInput)\n",
    "\n",
    "x = generator(ganInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator = AnimeDiscriminatorFactory().build((64, 64, 3))\n",
    "# discriminator.summary()\n",
    "# d_input = keras.layers.concatenate([x1, x2, x3], axis=-1)\n",
    "# d_input = Reshape((96, 96, 3))(d_input)\n",
    "# generator = Model(inputs=ganInput, outputs=d_input)\n",
    "# ganOutput = discriminator(d_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ganOutput = discriminator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dLosses = []\n",
    "gLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the loss from each batch\n",
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dLosses, label='Discriminitive loss')\n",
    "    # plt.plot(gLosses, label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('./collected_data/gan_loss_epoch_%d.png' % epoch)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a wall of generated MNIST images\n",
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, input_dim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 64, 64, 3)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./collected_data/gan_generated_image_epoch_%d.png' % epoch)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the generator and discriminator networks (and weights) for later use\n",
    "def saveModels(epoch):\n",
    "    print(\"saving\")\n",
    "    generator.save('./collected_models/gan_generator1_epoch_%d.h5' % epoch)\n",
    "    # generator1.save('./collected_models/gan_generator1_epoch_%d.h5' % epoch)\n",
    "    # generator2.save('./collected_models/gan_generator2_epoch_%d.h5' % epoch)\n",
    "    # generator3.save('./collected_models/gan_generator3_epoch_%d.h5' % epoch)\n",
    "    discriminator.save('./collected_models/gan_discriminator_epoch_%d.h5' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = int(images_train.shape[0] / batchSize)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', batchSize)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    valid_datagen = ImageDataGenerator(rescale = (1./255))\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='binary')\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        dloss = 0\n",
    "        gloss = 0\n",
    "        for batch, label in train_generator:\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, input_dim])\n",
    "            #imageBatch = images_train[np.random.randint(0, images_train.shape[0], size=batchSize)]\n",
    "\n",
    "            # Generate fake images\n",
    "            generatedImages = generator.predict(noise)\n",
    "            # print(np.shape(imageBatch), np.shape(generatedImages))\n",
    "            images = np.concatenate([batch, generatedImages])        \n",
    "            # print(X.shape)\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            labels = np.concatenate((label, np.ones(batchSize)))\n",
    "            \n",
    "            # Train discriminator\n",
    "            print(\"discriminator start...\", end=\"\")\n",
    "            discriminator.trainable = True\n",
    "            (dloss, dAcc) = discriminator.train_on_batch(images, labels)\n",
    "            print((dloss, dAcc))\n",
    "            print(\"done\")\n",
    "\n",
    "            # Train generator\n",
    "            print(\"generator start...\", end=\"\")\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, input_dim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "#             print('-'*5, 'Batch %d/%d done' % ((b + 1), batchCount))\n",
    "            print(\"done\")\n",
    "            break\n",
    "        \n",
    "        # Store loss of most recent batch from this epoch\n",
    "        dLosses.append(dloss)\n",
    "        gLosses.append(gloss)\n",
    "        \n",
    "        print(\"saving generated image...\", end=\"\")\n",
    "        for i in range(generatedImages.shape[0]):\n",
    "            g_image = array_to_img(generatedImages[i])\n",
    "            g_image.save(\"./collected_data/gan_generated_image_epoch_{0}_{1}.png\".format(e, i))\n",
    "        print(\"done\")\n",
    "        \n",
    "        \n",
    "        if e == 1 or e % 20 == 0:\n",
    "            print(\"saving model...\", end=\"\")\n",
    "            saveModels(e)\n",
    "            print(\"done\")\n",
    "\n",
    "        # Plot losses from every epoch\n",
    "        print(\"plotting losses...\", end=\"\")\n",
    "        plotLoss(e)\n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1\n",
      "Batch size: 2\n",
      "Batches per epoch: 25000\n",
      "Found 521 images belonging to 1 classes.\n",
      "Found 521 images belonging to 1 classes.\n",
      "--------------- Epoch 1 ---------------\n",
      "discriminator start...(5.511692, 0.5)\n"
     ]
    }
   ],
   "source": [
    "train(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.metrics_names\n",
    "gan.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, size=[1, 128])\n",
    "generatedImages = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = array_to_img(generatedImages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.save(\"./collected_models/test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 521 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bs = []\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=6,\n",
    "        class_mode='binary')\n",
    "i = 0\n",
    "for batch, label in train_generator:\n",
    "    if (i > 2):\n",
    "        break\n",
    "    bs.append(batch)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(bs[0], bs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
